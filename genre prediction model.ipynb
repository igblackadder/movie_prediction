{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting movie genre from a synopsis\n",
    "\n",
    "This is an interesting problem in machine learning combining **text analysis** and **multilabel prediction**.\n",
    "\n",
    "The result is a model with an excellent **average f1$_{micro}$ test score of 0.57**. The model is an ensemble of naive bayes, support vector machines, random forest and stochastic gradient descent reached after reached after wrangling the data and cross validating each approach seperately.\n",
    "\n",
    "Wrangling text data presents an interesting problem since you can't make a plot in 10000 dimensions. However by using mutual information functions to identify features that were overfitted (for example names and numbers) I improved the generalization of the fit.\n",
    "\n",
    "Multilabel classification is also a rich area of research. While some models can natively handle multiple labels (like random forests) most need adaptation. And to improve the f1 score I found that a thresholding function was needed which both varied the cutoff score required to predict a label and mandated a minimum number of predicted labels per movie.\n",
    "\n",
    "Brevity demands that I not show all of the dead ends that I pursued in this project. Where a decision appears precient I have attempted justify the choice in the surrounding text.\n",
    "\n",
    "The outline is as follows:\n",
    "\n",
    "1. The data is imported and prepped for analysis.\n",
    "2. The features are analysed and appropriate choices made to improve the fit.\n",
    "3. A dummy model is defined to create a reasonable benchmark\n",
    "4. Multilabel classification classes are defined to generalise single label models and provide adjustable cutoffs.\n",
    "5. A number of models are tested, with parameters found through cross validation.\n",
    "6. Test set result of final model\n",
    "7. A short discussion on future work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gordonblackadder/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import re as re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "\n",
    "#some useful distributions\n",
    "from scipy.stats import expon as sp_expon\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "#sklearn utilities\n",
    "from sklearn.base import MetaEstimatorMixin,BaseEstimator, TransformerMixin,ClassifierMixin\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MultiLabelBinarizer\n",
    "\n",
    "\n",
    "#Models  \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import movie data and prepare it for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two data files. One containing the basic information about the movie (name, country, genre etc) and another file containing the synopses. Let's import the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieData = pd.read_csv('movie.metadata.tsv', sep='\\t', header=0, encoding='utf-8',\n",
    "                        names=[\"WikipediaID\", \"FreebaseID\", \"name\", \"date\", \"boxOffice\", \"runtime\",\n",
    "                               \"languages\", \"countries\", \"genres\"],\n",
    "                        usecols=[\"WikipediaID\", \"name\", \"date\", \"languages\", \"countries\", \"genres\"],\n",
    "                        index_col=0)\n",
    "movieData.dropna(subset=['genres'], inplace=True)#this was found to improve the quality of the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what a sample of this data lookes like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                          The Hunger Games\n",
       "date                                                2012-03-12\n",
       "languages                   {\"/m/02h40lc\": \"English Language\"}\n",
       "countries            {\"/m/09c7w0\": \"United States of America\"}\n",
       "genres       {\"/m/03btsm8\": \"Action/Adventure\", \"/m/06n90\":...\n",
       "Name: 31186339, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieData.ix[31186339]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested specifically in predicting the genre of the movie, let's looks at that closer. The genre information is presented with some tagging information that we don't need, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{\"/m/03btsm8\": \"Action/Adventure\", \"/m/06n90\": \"Science Fiction\", \"/m/02kdv5l\": \"Action\", \"/m/07s9rl0\": \"Drama\"}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieData[\"genres\"].ix[31186339]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's just extract the genre information we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Mystery', u'Biographical film', u'Drama', u'Crime Drama']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractTags(string):\n",
    "    return re.findall('\"([\\w\\s]+)\"', string)\n",
    "\n",
    "movieData[\"genres\"] = movieData[\"genres\"].apply(extractTags)\n",
    "movieData[\"genres\"].ix[3196793]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same extractor to get the language and country tags, although neither the countries nor the languages will be used in the current analysis. In fact we are going to focus on predicting the genre for english language movies only, at least for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieData[\"languages\"] = movieData[\"languages\"].apply(extractTags)\n",
    "movieData[\"countries\"] = movieData[\"countries\"].apply(extractTags)\n",
    "\n",
    "isInEnglish = lambda langauges : u'English Language' in langauges\n",
    "movieData = movieData[movieData.languages.apply(isInEnglish)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import the synopsis data that we will use to predict the genres. First let's check the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23890098\tShlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\n",
      "31186339\tThe nation of Panem consists of a wealthy Capitol and twelve poorer districts. As punishment for a past rebellion, each district must provide a boy and girl  between the ages of 12 and 18 selected by lottery  for the annual Hunger Games. The tributes must fight to the death in an arena; the sole surviv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confidence': 0.99, 'encoding': 'utf-8'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_object  = open('plot_summaries.txt', 'r')\n",
    "print file_object.read(500) \n",
    "rawdata = file_object.read()\n",
    "chardet.detect(rawdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confident that the data is in the standard utf-8 format, let's import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot = pd.read_csv(\"plot_summaries.txt\", sep='\\t', encoding='utf-8', \n",
    "                   names=[\"ident\", \"synopsis\"], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary data simply contains the ID number and the synopsis, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "synopsis    The nation of Panem consists of a wealthy Capi...\n",
       "Name: 31186339, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot.ix[31186339]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the two files, pairing each movie with its synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31186339</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>2012-03-12</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Science Fiction, Action, Drama]</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231378</th>\n",
       "      <td>The Lemon Drop Kid</td>\n",
       "      <td>1951-03-08</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Screwball comedy, Comedy]</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595909</th>\n",
       "      <td>A Cry in the Dark</td>\n",
       "      <td>1988-11-03</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America, Australia, New Zeal...</td>\n",
       "      <td>[Crime Fiction, Drama, Docudrama, World cinema...</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272176</th>\n",
       "      <td>End Game</td>\n",
       "      <td>2006</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America, Canada, Germany]</td>\n",
       "      <td>[Thriller, Action, Drama]</td>\n",
       "      <td>The president is on his way to give a speech. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952976</th>\n",
       "      <td>Dark Water</td>\n",
       "      <td>2005-06-27</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Drama, Horror]</td>\n",
       "      <td>{{plot}} The film opens in 1974, as a young gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name        date           languages  \\\n",
       "31186339    The Hunger Games  2012-03-12  [English Language]   \n",
       "2231378   The Lemon Drop Kid  1951-03-08  [English Language]   \n",
       "595909     A Cry in the Dark  1988-11-03  [English Language]   \n",
       "5272176             End Game        2006  [English Language]   \n",
       "1952976           Dark Water  2005-06-27  [English Language]   \n",
       "\n",
       "                                                  countries  \\\n",
       "31186339                         [United States of America]   \n",
       "2231378                          [United States of America]   \n",
       "595909    [United States of America, Australia, New Zeal...   \n",
       "5272176         [United States of America, Canada, Germany]   \n",
       "1952976                          [United States of America]   \n",
       "\n",
       "                                                     genres  \\\n",
       "31186339                   [Science Fiction, Action, Drama]   \n",
       "2231378                          [Screwball comedy, Comedy]   \n",
       "595909    [Crime Fiction, Drama, Docudrama, World cinema...   \n",
       "5272176                           [Thriller, Action, Drama]   \n",
       "1952976                           [Thriller, Drama, Horror]   \n",
       "\n",
       "                                                   synopsis  \n",
       "31186339  The nation of Panem consists of a wealthy Capi...  \n",
       "2231378   The Lemon Drop Kid , a New York City swindler,...  \n",
       "595909    Seventh-day Adventist Church pastor Michael Ch...  \n",
       "5272176   The president is on his way to give a speech. ...  \n",
       "1952976   {{plot}} The film opens in 1974, as a young gi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(movieData, plot, left_index=True, right_index=True, how='inner')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the training labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to transform the training labels. At the moment they look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31186339    [Science Fiction, Action, Drama]\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.genres[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels need to be binarized so that each genre is represented by a column and a film with a given genre is represented by a 1 in the approriate column. However there are over 300 genres listed in the wikipedia data and not all of them are what we might typically think of as a genre. They can be a detail of the movie content such as 'Airplanes and airports', tell you the place or language of the movie, like 'Bengali Cinema', or even the ditribution, e.g. u'Roadshow theatrical release'. Such descriptions are not really genres and so should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toDelete = [u'Absurdism', u'Airplanes and airports', u'Albino bias',u'Americana',u'Animal Picture',u'Animals',u'Anthology', u'Anthropology', u'Archaeology',u'Archives and records',u'Art film', u'Beach Film',u'Beach Party film', u'Bengali Cinema',u'Blaxploitation', u'Bollywood',u'British Empire Film', u'British New Wave',u'Buddy film',u'Business', u'Camp',u'Cavalry Film', u'Chase Movie', u'Chinese Movies',u'Christmas movie',u'Cold War',u'Coming of age', u'Computers',u'Cult',u'Cyberpunk', u'Dogme 95', u'Doomsday film',u'Early Black Cinema',u'Education', u'Educational', u'Environmental Science',u'Ensemble Film', u'Escape Film', u'Essay Film', u'Existentialism',u'Experimental film', u'Exploitation', u'Expressionism', u'Fan film', u'Feature film', u'Female buddy film', u'Feminist Film', u'Fictional film', u'Filipino', u'Filipino Movies', u'Film', u'Film adaptation',u'Filmed Play', u'Foreign legion',u'Giallo',u'Goat gland', u'Gothic Film',u'Gross out',u'Hagiography', u'Holiday Film', u'Indie', u'Japanese Movies', u'Journalism',u'Jungle Film', u'Juvenile Delinquency Film',\n",
    "            u'Kafkaesque', u'Kitchen sink realism', u'Latino', u'Libraries and librarians', u'Linguistics',u'Live action',u'Media Studies',u'Medical fiction',u'Mondo film',u'Movie serial',u'Mumblecore',u'Nature',u'New Hollywood', u'News',u'Northern', u'Nuclear warfare', u'Parkour in popular culture',u'Patriotic film', \n",
    "            u'Pinku eiga', u'Plague', u'Point of view shot',u'Prison',u'Private military company',u'Propaganda film',u'Reboot', u'Remake', u'Religious Film',u'Roadshow theatrical release',\n",
    "            u'School story', u'Sexploitation', u'Sponsored film', u'Short Film',u'Singing cowboy', u'Slice of life story',u'Social issues', u'Social problem film', u'Sponsored film', u'Star vehicle',u'Statutory rape', u'Steampunk', u'Stoner film',u'Superhero', u'Superhero movie', u'Surrealism',u'Sword and Sandal', u'Sword and sorcery', u'Sword and sorcery films',  u'Television movie', u'The Netherlands in World War II',u'Tragedy', u'Travel', u'World cinema', u'Wuxia',u'Z movie'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other times the genre listed can be a combinatation of several genres and so should be categorised as both seperately. This means replacing 'Action Comedy' with 'Action' and 'Comedy', and 'Alien Film' with 'Creature Film' and'Science Fiction'. Furthermore we can identify subgenres and categorise by the parent genre, for example by replacing 'Parody' with 'Comedy'. And finally we can idnetify missspellings and plurals (replacing 'Sport' with 'Sports' and 'Comdedy' with 'Comedy')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toReplace = [(u'Acid western', [u'Western']),(u'Action Comedy', [u'Action', u'Comedy']),(u'Action Thrillers', [u'Action', u'Thriller']),(u'Addiction Drama', [u'Drama']),(u'Adventure Comedy',[u'Adventure', u'Comedy']),(u'Alien Film', [u'Creature Film', u'Science Fiction']),(u'Alien invasion', [u'Creature Film', u'Science Fiction']),(u'Animated Musical', [u'Animation']),(u'Animated cartoon', [u'Animation']),(u'Anime', [u'Animation']),(u'Auto racing', [u'Sports']),(u'Backstage Musical', [u'Musical']),(u'Baseball', [u'Sports']),(u'Biker Film', [u'Road movie']),(u'Biographical film', [u'Biography']),(u'Black comedy', [u'Comedy']),(u'Boxing', [u'Sports']),(u'Breakdance', [u'Dance']),(u'Buddy cop', [u'Crime']),(u'Caper story', [u'Crime', u'Comedy']),(u'Chick flick', [u'Romance']),(u'Childhood Drama',[u'Drama']),(u'Christian film', [u'Religious Film']),(u'Clay animation', [u'Animation']),\n",
    "             (u'Combat Films', [u'Action']),(u'Comdedy',[u'Comedy']),(u'Comedy Thriller', [u'Comedy', u'Thriller']),(u'Comedy Western', [u'Comedy', u'Western']),(u'Comedy film', [u'Comedy']),(u'Comedy horror', [u'Comedy', u'Horror']),(u'Comedy of Errors', [u'Comedy']),(u'Comedy of manners', [u'Comedy']),(u'Computer Animation', [u'Animation']),(u'Concert film', [u'Music']),(u'Conspiracy fiction', [u'Thriller']),(u'Costume Adventure', [u'Adventure']),(u'Costume Horror', [u'Horror']),(u'Costume drama', [u'Drama']),(u'Courtroom Comedy',[u'Courtroom', u'Comedy']),(u'Courtroom Drama',[u'Courtroom', u'Drama']),(u'Creature Film', [u'Monster']), (u'Crime Comedy', [u'Crime', u'Comedy']),(u'Crime Drama', [u'Crime', u'Drama']),(u'Crime Fiction', [u'Crime']),(u'Crime Thriller', [u'Crime', u'Thriller']),(u'Demonic child', [u'Horror']),(u'Detective fiction', [u'Detective']),(u'Docudrama', [u'Drama']),(u'Domestic Comedy', [u'Comedy']),(u'Ealing Comedies', [u'Comedy']),(u'Epic Western', [u'Epic', u'Western']),(u'Erotic Drama', [u'Adult', u'Drama']),(u'Erotic thriller', [u'Adult', u'Thriller']),(u'Erotica', [u'Adult']),(u'Extreme Sports', [u'Sports']),(u'Family Drama', [u'Family Film', u'Drama']),\n",
    "             (u'Fairy Tale', [u'Fantasy']),(u'Fairy tale', [u'Fantasy']),(u'Fantasy Adventure', [u'Fantasy', u'Adventure']),(u'Fantasy Comedy', [u'Fantasy', u'Comedy']),(u'Fantasy Drama', [u'Fantasy', u'Drama']),(u'Future noir', [u'Film noir']),(u'Gangster Film', [u'Crime']),(u'Gay', [u'LGBT']),(u'Gay Interest', [ u'LGBT']),(u'Gay Themed', [ u'LGBT']), (u'Gay pornography', [ u'LGBT', u'Adult']),(u'Gender Issues', [u'LGBT']),(u'Glamorized Spy Film', [u'Spy']),\n",
    "             (u'Gulf War', [u'War film']),(u'Haunted House Film', [u'Horror']),(u'Hardcore pornography', [u'Adult']),(u'Heavenly Comedy', [u'Comedy']),(u'Heist', [u'Crime']),(u'Hip hop movies', [u'Music']),(u'Historical Documentaries', [u'History', u'Documentary']),(u'Historical Epic', [u'History']),(u'Historical drama', [u'History']),(u'Historical Drama', [u'History', u'Drama']),(u'Historical fiction', [u'History']),(u'Homoeroticism', [u'Adult', u'LGBT']),(u'Horror Comedy', [u'Horror', u'Comedy']),(u'Horse racing', [u'Sport']),(u'Humour', [u'Comedy']),(u'Hybrid Western', [u'Western']),(u'Indian Western', [u'Western']),(u'Inspirational Drama', [u'Drama']),(u'Instrumental Music', [u'Music']),(u'Interpersonal Relationships', [u'Drama']),(u'Jukebox musical', [u'Musical']),(u'Legal drama', [u'Courtroom']),(u'Marriage Drama', [u'Drama']),(u'Master Criminal Films', [u'Crime']),(u'Media Satire', [u'Comedy']),\n",
    "             (u'Melodrama', [u'Drama']),(u'Mockumentary', [u'Comedy']),(u'Monster movie', [u'Monster']),(u'Movies About Gladiators', [u'History', u'Action']),(u'Musical Drama', [u'Musical', u'Drama']),(u'Musical comedy', [u'Musical', u'Comedy']), (u'Mythological Fantasy',[u'Fantasy']),(u'Natural disaster', [u'Disaster']), (u'Natural horror films', [u'Horror']),(u'Ninja movie', [u'Martial Arts Film']),(u'Operetta', [u'Musical']),(u'Outlaw', [u'Crime']),(u'Outlaw biker film', [u'Crime', u'Road movie']),(u'Parody', [u'Comedy']),(u'Period Horror', [u'Period', u'Horror']),(u'Period piece', [u'Period']),(u'Political cinema', [u'Politics']),(u'Political drama', [u'Politics', u'Drama']),(u'Political satire', [u'Politics', u'Comedy']),(u'Political thriller', [u'Politics', u'Thriller']),(u'Pornographic movie', [u'Adult']),(u'Pornography', [u'Adult']),(u'Prison', [u'Crime']),(u'Prison escape', [u'Crime']),(u'Prison film', [u'Crime']),(u'Psychological horror', [u'Horror']),(u'Psychological thriller', [u'Thriller']),\n",
    "             (u'Punk rock', [u'Music']),(u'Race movie', ['Sports']),(u'Revisionist Fairy Tale', [u'Fantasy']),(u'Revisionist Western', [u'Western']),(u'Rockumentary', [u'Documentary', u'Music']),(u'Romance Film', [u'Romance']),(u'Romantic Film', [u'Romance']),(u'Romantic comedy', [u'Romance', u'Comedy']),(u'Romantic drama', [u'Romance', u'Drama']),(u'Romantic fantasy', [u'Romance', u'Fantasy']),(u'Samurai cinema', [u'Martial Arts Film']),(u'Satire', [u'Comedy']),(u'Sci Fi Pictures original films', [u'Science Fiction']),(u'Science fiction Western', [u'Science Fiction', u'Western']),(u'Screwball comedy', [u'Comedy']),(u'Sex comedy', [u'Comedy']),(u'Slapstick', [u'Comedy']),(u'Slasher', [u'Horror']),(u'Softcore Porn', [u'Adult']),(u'Space opera', [u'Science Fiction', u'Musical']),(u'Space western', [u'Science Fiction', u'Western']),(u'Spaghetti Western', [u'Western']),(u'Spaghetti western', [u'Western']),(u'Splatter film', [u'Horror']),(u'Sport', [ u'Sports']),(u'Stop motion', [u'Animation']),(u'Supermarionation', [u'Animation']),(u'Swashbuckler films', [u'Adventure']),\n",
    "             (u'Therimin music', [u'Music']), (u'Time travel', [u'Science Fiction']),(u'Tragicomedy', [u'Comedy', u'Tragedy']),(u'Vampire movies', [u'Horror']),(u'War effort', [u'War film']),(u'Werewolf fiction', [u'Monster']),(u'Whodunit', [u'Detective']),(u'Women in prison films', [u'Prison']),(u'World History', [u'History']),(u'Workplace Comedy', [u'Comedy']),(u'Zombie Film', [u'Monster'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions can remove and replace genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class wordRemover():\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "        \n",
    "    def removeWord(self, listOfWords):\n",
    "        if self.word in listOfWords:\n",
    "            index = listOfWords.index(self.word)\n",
    "            del listOfWords[index]\n",
    "        return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class wordReplacer():\n",
    "    def __init__(self, word, replacements):\n",
    "        self.word = word\n",
    "        self.replacements = replacements\n",
    "        \n",
    "    def replaceWord(self, listOfWords):\n",
    "        if self.word in listOfWords:\n",
    "            index = listOfWords.index(self.word)\n",
    "            del listOfWords[index]\n",
    "            for replacement in self.replacements:\n",
    "                if replacement not in listOfWords:\n",
    "                    listOfWords.append(replacement)\n",
    "        return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in toDelete:\n",
    "    result.genres = result.genres.apply(wordRemover(word).removeWord)\n",
    "\n",
    "for word, replacements in toReplace:\n",
    "    result.genres = result.genres.apply(wordReplacer(word, replacements).replaceWord)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now binarize the data and find a total of 40 different genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binarizer = MultiLabelBinarizer()\n",
    "y = binarizer.fit_transform(result.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Action', u'Adult', u'Adventure', u'Animation', u'Biography',\n",
       "       u'Comedy', u'Courtroom', u'Crime', u'Dance', u'Detective',\n",
       "       u'Disaster', u'Documentary', u'Drama', u'Dystopia', u'Epic',\n",
       "       u'Family Film', u'Fantasy', u'Film noir', u'History', u'Horror',\n",
       "       u'LGBT', u'Martial Arts Film', u'Monster', u'Music', u'Musical',\n",
       "       u'Mystery', u'Period', u'Politics', u'Prison', u'Religious Film',\n",
       "       u'Road movie', u'Romance', u'Science Fiction', u'Silent film',\n",
       "       u'Sports', u'Spy', u'Supernatural', u'Suspense', u'Teen',\n",
       "       u'Thriller', u'Tragedy', u'War film', u'Western'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genre data is stored as ones and zeros e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can easily see what genres this vector corresponds to by doing an inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Action', u'Drama', u'Science Fiction')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.inverse_transform(y[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is some leakage from the training set to the test set by binarizing the data before the test train split. In practice this has no affect since we canot fit genres which aren't in the training set and so we will just predict false on all such genres not present in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data set into training and test sets. We won't look at the test set again till the very end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(result.synopsis,y,\n",
    "                                                    train_size=0.7, random_state = 9588)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's look at the distribution of genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x117b75ad0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEdCAYAAAAIIcBlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104eb0810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelCounts = y_train.sum(axis=0)\n",
    "n, bins, patches = plt.hist(labelCounts, bins=np.logspace(1, 4, 9))\n",
    "plt.semilogx()\n",
    "plt.title(\"Distribution of genre counts\")\n",
    "plt.xlabel(\"Number of movies with given genre\")\n",
    "plt.ylabel(\"Number of genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are a handful of genres that appear in the training set less than a hundred times and some that appear many thousands of times with most appearing several hundred times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature analysis and wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I want to do some text wrangling as we prepare the synopsis for predictive analysis. It is helpful to do this in the context of just a single label. I will initially use Comedy as it describes a significant portion of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35782250158583706"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genreDF = pd.DataFrame(y_train, columns = binarizer.classes_)\n",
    "genreDF.Comedy.sum()/genreDF.Comedy.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's wrangle the text. \n",
    "\n",
    "First, a review of the text shows that some of the data contains tags such as \"{{plot}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{{plot}} The film opens '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.ix[1952976][:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact these tags are contained in almost 5% of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045787440170693729"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.str.contains(\"{{\\w*}}\", case=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't just want to delete these tags once, we want easily manageable code to eventually create a data wrangling pripeline. So I'll create a transformer to delete these tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deleteSynopsisTags(X):\n",
    "    return X.str.replace(\"\\s*{{\\w*}}\\s*\", \"\", case=False)\n",
    "\n",
    "deleteSynopsisTagsTransformer = FunctionTransformer(deleteSynopsisTags, validate=False)\n",
    "\n",
    "X_wrangle_1 = deleteSynopsisTagsTransformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see that the tags have now gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The film opens in 1974, '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wrangle_1.ix[1952976][:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I want to start making fits to the Comedy genre data, identifying the most important features and so finding possible sources of error. \n",
    "\n",
    "First though I need to choose an appropraite score to measure the fit quality. I will choose the micro f1 score which balanaces precision (reducing false negatives) and accuracy (reducing false positives). The is implemented here for a single label (Later I will extend this to multilabel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def customF1(hat, actual, **kwargs):\n",
    "    accuracy = ((actual*hat).sum())/actual.sum()\n",
    "    precision = ((actual*hat).sum())/hat.sum()\n",
    "    if accuracy==0 or precision==0:\n",
    "        f1= 0\n",
    "    else:\n",
    "        f1= 2.* pow(pow(accuracy, -1) + pow(precision, -1), -1)\n",
    "    return f1\n",
    "customF1Scorer = make_scorer(customF1, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's identify the most important features and the quality of the fit. The folloiwng code vectorizes the synopsis, and prints out the 200 most important words for determing whether a movie is a comedy using a $\\chi^2$ imformation metric. Next we perform a fit over the most important features and print the resulting cross validation score and training score. By printing both we will identify possible overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mostImportantFeatrures(X, y):\n",
    "    count = CountVectorizer(lowercase=False, strip_accents='unicode', min_df = 3, stop_words='english')\n",
    "    #print the most important features\n",
    "    selector = SelectKBest(chi2, 200)\n",
    "    X_Vec = count.fit_transform(X, y)\n",
    "    X_select = selector.fit_transform(X_Vec, y)\n",
    "    print np.unique([name for name, val in zip(count.get_feature_names(), \n",
    "                                               selector.get_support()) \n",
    "                     if val==True])\n",
    "    #get a fit score based on the most important featrures\n",
    "    MultinomialPipe = Pipeline([\n",
    "                                (\"count\", count),\n",
    "                                (\"selector\", SelectPercentile(chi2)),\n",
    "                                (\"model\", MultinomialNB(alpha = 1e-9, fit_prior=False))\n",
    "                               ])\n",
    "    rs = RandomizedSearchCV(MultinomialPipe, param_distributions={\"selector__percentile\":sp_randint(1, 50)}, \n",
    "                            n_iter=10,\n",
    "                            scoring=customF1Scorer, verbose=0, \n",
    "                            refit=True, n_jobs=-1, \n",
    "                            cv=3\n",
    "                           )\n",
    "    rs.fit(X, y)\n",
    "    print \"grid search best score = \", rs.best_score_\n",
    "    print \"grid search best param = \", rs.best_params_ \n",
    "    hYat = rs.predict(X)\n",
    "    print \"score on training data = \", customF1(y, hYat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Adam' u'Alfalfa' u'Alfie' u'Ambrose' u'Andy' u'Augie' u'Babe'\n",
      " u'Beethoven' u'Beverly' u'Big' u'Bishop' u'Bob' u'Bond' u'Boris'\n",
      " u'British' u'Buddy' u'Bugs' u'Butch' u'Buzz' u'Calvin' u'Captain' u'Cash'\n",
      " u'Charlie' u'Cheech' u'Chester' u'Chip' u'Chuck' u'Chucky' u'Clouseau'\n",
      " u'Coyote' u'Curly' u'Cynthia' u'Daffy' u'Dave' u'Dewey' u'Dexter'\n",
      " u'Dickie' u'Dr' u'Dreyfus' u'Elliot' u'Elmer' u'Elwood' u'Ernest' u'Ernie'\n",
      " u'Evan' u'Evil' u'Fitz' u'Garfield' u'George' u'Georgia' u'German'\n",
      " u'Gidget' u'Gonzo' u'Harold' u'Herbie' u'Hollywood' u'Ira' u'Jackie'\n",
      " u'Jacob' u'Japanese' u'Jerry' u'John' u'Joseph' u'Josh' u'Junior' u'Ka'\n",
      " u'Kui' u'Larry' u'Loretta' u'Louie' u'Madea' u'Madonna' u'Mame' u'Martin'\n",
      " u'Massie' u'Miss' u'Moe' u'Monty' u'Mr' u'Murtaugh' u'Neha' u'Ollie'\n",
      " u'Oscar' u'Pink' u'Popeye' u'Porky' u'Ralph' u'Ramona' u'Riggs' u'Roger'\n",
      " u'Sach' u'Sam' u'Sharpay' u'Shemp' u'Shrek' u'Slip' u'Spanky' u'Speedy'\n",
      " u'Spike' u'Stan' u'Stooges' u'TV' u'Tarzan' u'Tom' u'Wally' u'War'\n",
      " u'Wilby' u'Wolf' u'Woody' u'accidentally' u'aircraft' u'attack'\n",
      " u'attacked' u'attacks' u'audience' u'ball' u'band' u'battle' u'best'\n",
      " u'bet' u'blood' u'body' u'boyfriend' u'boys' u'cartoon' u'cat' u'comedy'\n",
      " u'company' u'creature' u'credits' u'dance' u'date' u'dating' u'dead'\n",
      " u'death' u'decide' u'decides' u'dies' u'dinner' u'dog' u'end' u'ends'\n",
      " u'evidence' u'feelings' u'forces' u'friends' u'gets' u'getting'\n",
      " u'girlfriend' u'girls' u'gun' u'happy' u'hockey' u'idea' u'investigation'\n",
      " u'job' u'kids' u'kill' u'killed' u'killer' u'killing' u'kills' u'kiss'\n",
      " u'married' u'men' u'military' u'mom' u'money' u'mouse' u'movie' u'murder'\n",
      " u'murdered' u'murders' u'new' u'parents' u'party' u'play' u'prom'\n",
      " u'restaurant' u'scheme' u'school' u'sex' u'ship' u'shoots' u'shot'\n",
      " u'singing' u'soldiers' u'son' u'song' u'store' u'studio' u'survivors'\n",
      " u'troops' u'village' u'war' u'wedding' u'win' u'women' u'wounded' u'young']\n",
      "score on training data =  0.764185703758\n"
     ]
    }
   ],
   "source": [
    "mostImportantFeatrures(X_wrangle_1, genreDF.Comedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that many of the most important features are names. While we might imagine that a few names could hold some predictive power, the use of names seems likely to contribute to the overfitting we observe. Lets remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'accidentally' u'actor' u'actors' u'advertising' u'advice' u'aircraft'\n",
      " u'alive' u'antics' u'army' u'aspiring' u'attack' u'attacked' u'attacks'\n",
      " u'audience' u'awkward' u'bachelor' u'ball' u'band' u'battle' u'best'\n",
      " u'bet' u'big' u'bird' u'blood' u'body' u'bong' u'boyfriend' u'boys'\n",
      " u'bumbling' u'butler' u'canary' u'carrot' u'cartoon' u'cat' u'cave'\n",
      " u'ceremony' u'chase' u'chef' u'child' u'class' u'club' u'college'\n",
      " u'comedy' u'comic' u'command' u'commander' u'company' u'competition'\n",
      " u'contest' u'cow' u'creature' u'credits' u'crime' u'crooks' u'crush'\n",
      " u'dad' u'dance' u'date' u'dates' u'dating' u'daughter' u'dead' u'death'\n",
      " u'decide' u'decides' u'dentist' u'die' u'died' u'dies' u'dinner' u'doesn'\n",
      " u'dog' u'drug' u'duo' u'dying' u'eccentric' u'end' u'ends' u'escape'\n",
      " u'evidence' u'ex' u'executed' u'fatally' u'feelings' u'fired' u'forces'\n",
      " u'friends' u'fun' u'game' u'gets' u'getting' u'gig' u'girlfriend' u'girls'\n",
      " u'golf' u'gun' u'guys' u'happy' u'having' u'hockey' u'hospital' u'hotel'\n",
      " u'human' u'idea' u'inept' u'infected' u'investigation' u'job' u'just'\n",
      " u'kids' u'kill' u'killed' u'killer' u'killing' u'kills' u'kiss' u'knife'\n",
      " u'likes' u'limo' u'love' u'make' u'man' u'manager' u'marijuana' u'married'\n",
      " u'men' u'military' u'mishaps' u'mission' u'mistaken' u'mom' u'money'\n",
      " u'mouse' u'movie' u'murder' u'murdered' u'murders' u'musical' u'new'\n",
      " u'officer' u'orders' u'parents' u'parody' u'party' u'pay' u'penguins'\n",
      " u'performance' u'play' u'police' u'prisoner' u'prisoners' u'producer'\n",
      " u'prom' u'raped' u'reconcile' u'remaining' u'restaurant' u'scheme'\n",
      " u'school' u'script' u'sea' u'sex' u'ship' u'shoots' u'shop' u'shot'\n",
      " u'sing' u'singing' u'soldier' u'soldiers' u'son' u'song' u'spend' u'stabs'\n",
      " u'stage' u'star' u'store' u'studio' u'summer' u'survive' u'survivor'\n",
      " u'survivors' u'talent' u'tortured' u'trio' u'troops' u'victim' u'victims'\n",
      " u'village' u'visions' u'war' u'wedding' u'win' u'winning' u'women' u'woo'\n",
      " u'wounded' u'wounds' u'years' u'young']\n",
      "grid search best score =  0.654921847675\n",
      "grid search best param =  {'selector__percentile': 10}\n",
      "score on training data =  0.704650665907\n"
     ]
    }
   ],
   "source": [
    "def noCaps(X):\n",
    "    return X.str.replace(r'([A-Z])\\w+', \"\", case=True)\n",
    "\n",
    "noCapsTransform = FunctionTransformer(noCaps, validate=False)\n",
    "\n",
    "X_wrangle_2 = noCapsTransform.fit_transform(X_wrangle_1)\n",
    "mostImportantFeatrures(X_wrangle_2, genreDF.Comedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced overfitting by quite a bit, although it would have been better if this gain had come from increased predictive power rather than reducing the training score. \n",
    "\n",
    "Next, we see a number of very similar words appearing, perhaps suggesting that we should use stemming to improve the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'accident' u'actor' u'advertis' u'advic' u'aircraft' u'aliv' u'ambush'\n",
      " u'antic' u'apolog' u'arm' u'armi' u'attack' u'audienc' u'awkward'\n",
      " u'bachelor' u'ball' u'band' u'battl' u'best' u'bet' u'big' u'black'\n",
      " u'blood' u'bodi' u'boyfriend' u'brutal' u'bumbl' u'burn' u'butler' u'buy'\n",
      " u'canari' u'carrot' u'cartoon' u'cat' u'cave' u'chase' u'cheerlead'\n",
      " u'chef' u'child' u'class' u'colleg' u'comedi' u'comic' u'command'\n",
      " u'compani' u'competit' u'contest' u'costum' u'creatur' u'credit' u'crime'\n",
      " u'dad' u'danc' u'dark' u'date' u'dead' u'death' u'decid' u'demon'\n",
      " u'dentist' u'desert' u'destroy' u'die' u'dinner' u'disguis' u'doesn'\n",
      " u'dog' u'dragon' u'dress' u'drug' u'eccentr' u'embarrass' u'end' u'enemi'\n",
      " u'escap' u'everyon' u'evid' u'ex' u'fatal' u'feel' u'fight' u'fighter'\n",
      " u'forc' u'friend' u'fun' u'girlfriend' u'golf' u'gun' u'guy' u'happi'\n",
      " u'helicopt' u'hockey' u'hospit' u'hotel' u'human' u'idea' u'impress'\n",
      " u'inadvert' u'inept' u'infect' u'investig' u'job' u'kid' u'kill' u'killer'\n",
      " u'kiss' u'knife' u'ladi' u'laugh' u'lot' u'love' u'make' u'man'\n",
      " u'marijuana' u'marri' u'men' u'militari' u'mishap' u'missil' u'mission'\n",
      " u'mistak' u'mom' u'money' u'mous' u'movi' u'murder' u'music' u'nerd'\n",
      " u'new' u'obnoxi' u'parent' u'parodi' u'parti' u'pay' u'penguin' u'perform'\n",
      " u'pie' u'pilot' u'plan' u'play' u'polic' u'pop' u'popular' u'power'\n",
      " u'prison' u'produc' u'product' u'prom' u'propos' u'protect' u'quit'\n",
      " u'rape' u'reconcil' u'relationship' u'remain' u'restaur' u'roommat'\n",
      " u'scheme' u'school' u'script' u'sell' u'sex' u'ship' u'shoot' u'shop'\n",
      " u'shot' u'sing' u'sniper' u'soldier' u'son' u'song' u'spend' u'stab'\n",
      " u'star' u'store' u'studio' u'submarin' u'surviv' u'survivor' u'suspect'\n",
      " u'talent' u'ticket' u'togeth' u'tortur' u'trick' u'trio' u'troop'\n",
      " u'victim' u'villag' u'virgin' u'vision' u'wa' u'war' u'weapon' u'wed'\n",
      " u'win' u'women' u'woo' u'wound' u'young']\n",
      "grid search best score =  0.655833063577\n",
      "grid search best param =  {'selector__percentile': 21}\n",
      "score on training data =  0.706486101212\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "from nltk import tokenize\n",
    "stemmer = PorterStemmer()\n",
    "tokenizer = tokenize.WordPunctTokenizer()\n",
    "def stemCustom(X):\n",
    "    splitStemJoin = lambda string: ' '.join([stemmer.stem(word) for word in tokenizer.tokenize(string)])\n",
    "    return X.apply(splitStemJoin)\n",
    "\n",
    "stemTransform = FunctionTransformer(stemCustom, validate=False)\n",
    "\n",
    "X_wrangle_3 = stemTransform.fit_transform(X_wrangle_2)\n",
    "mostImportantFeatrures(X_wrangle_3, genreDF.Comedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we appear to have reduced overfitting but without improving the actual fit. Let's try looking at a different genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'02' u'09' u'1976' u'1980' u'1990' u'1995' u'1996' u'1999' u'2000'\n",
      " u'2001' u'2002' u'2003' u'2004' u'2006' u'2007' u'2008' u'2009' u'2010'\n",
      " u'2011' u'3D' u'41' u'accessd' u'activist' u'agre' u'al' u'album' u'alleg'\n",
      " u'archiv' u'arriv' u'art' u'ask' u'attack' u'attempt' u'away' u'bailout'\n",
      " u'becom' u'befor' u'began' u'billion' u'bodybuild' u'booksel' u'break'\n",
      " u'camera' u'car' u'censorship' u'chase' u'chronicl' u'cite' u'clip' u'com'\n",
      " u'come' u'commentari' u'contemporari' u'context' u'contribut'\n",
      " u'controversi' u'coral' u'cove' u'cub' u'cultur' u'daughter' u'dead'\n",
      " u'decad' u'decid' u'deficit' u'democraci' u'democrat' u'demonstr'\n",
      " u'deregul' u'describ' u'die' u'director' u'discov' u'discuss' u'document'\n",
      " u'documentari' u'doe' u'dolphin' u'econom' u'economist' u'ere' u'escap'\n",
      " u'eugen' u'evolut' u'examin' u'explor' u'fall' u'father' u'featur' u'film'\n",
      " u'filmmak' u'flamingo' u'focu' u'focus' u'footag' u'friend' u'genocid'\n",
      " u'genr' u'girl' u'global' u'goe' u'gun' u'ha' u'head' u'help' u'hi'\n",
      " u'hide' u'highlight' u'histor' u'histori' u'home' u'hous' u'html' u'http'\n",
      " u'humpback' u'husband' u'hydrogen' u'includ' u'indi' u'industri'\n",
      " u'interview' u'interviewe' u'issu' u'just' u'kill' u'know' u'largest'\n",
      " u'learn' u'leav' u'liftoff' u'love' u'mainstream' u'make' u'man' u'manag'\n",
      " u'market' u'marri' u'media' u'meet' u'midwif' u'montag' u'movement'\n",
      " u'murder' u'nation' u'night' u'offic' u'onli' u'order' u'org' u'pioneer'\n",
      " u'plan' u'polar' u'polic' u'polici' u'polio' u'polit' u'politician'\n",
      " u'pride' u'realiz' u'recycl' u'ref' u'retrospect' u'return' u'reveal'\n",
      " u'ringsid' u'room' u'run' u'save' u'send' u'shoot' u'shown' u'solar'\n",
      " u'son' u'soon' u'stop' u'tell' u'tenac' u'titl' u'today' u'tour'\n",
      " u'tourism' u'town' u'tradit' u'transit' u'tri' u'trillion' u'turn'\n",
      " u'union' u'unpreced' u'url' u'variou' u'verite' u'violenc' u'walru'\n",
      " u'want' u'web' u'western' u'whale' u'wife' u'www']\n",
      "grid search best score =  0.382406222288\n",
      "grid search best param =  {'selector__percentile': 22}\n",
      "score on training data =  0.503945291952\n"
     ]
    }
   ],
   "source": [
    "mostImportantFeatrures(X_wrangle_3, genreDF.Documentary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the fit is very much worse than for comedy. Also notice notice the presence of numbers which could be a source of error so let's try removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noDigits(X):\n",
    "    return X.str.replace(r'\\d+\\,?\\.?\\d?', \"\")\n",
    "\n",
    "noDigitsTransform = FunctionTransformer(noDigits, validate=False)\n",
    "\n",
    "X_wrangle_4 = noDigitsTransform.fit_transform(X_wrangle_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'accessd' u'activist' u'agre' u'al' u'album' u'alleg' u'anoth' u'anti'\n",
      " u'apart' u'archiv' u'arriv' u'art' u'ask' u'attack' u'attempt' u'away'\n",
      " u'bailout' u'becom' u'befor' u'began' u'billion' u'bodybuild' u'booksel'\n",
      " u'boy' u'break' u'calf' u'camera' u'car' u'caus' u'censorship' u'chase'\n",
      " u'chronicl' u'cite' u'clip' u'coalit' u'com' u'come' u'commentari'\n",
      " u'contemporari' u'context' u'contribut' u'controversi' u'coral' u'cove'\n",
      " u'cub' u'cultur' u'daughter' u'dead' u'decad' u'decid' u'deficit'\n",
      " u'democraci' u'democrat' u'demonstr' u'depict' u'deregul' u'describ'\n",
      " u'die' u'director' u'discov' u'discuss' u'document' u'documentari' u'doe'\n",
      " u'dolphin' u'econom' u'economist' u'ere' u'escap' u'eugen' u'evolut'\n",
      " u'examin' u'excerpt' u'explor' u'fall' u'father' u'featur' u'fight'\n",
      " u'film' u'filmmak' u'flamingo' u'focu' u'focus' u'footag' u'friend'\n",
      " u'genocid' u'genr' u'girl' u'global' u'goe' u'gun' u'ha' u'head' u'health'\n",
      " u'help' u'hi' u'hide' u'highlight' u'histor' u'histori' u'home' u'hous'\n",
      " u'hr' u'html' u'http' u'humpback' u'husband' u'hydrogen' u'includ' u'indi'\n",
      " u'industri' u'interspers' u'interview' u'interviewe' u'interweav' u'issu'\n",
      " u'job' u'just' u'kill' u'know' u'largest' u'learn' u'leav' u'liftoff'\n",
      " u'love' u'mainstream' u'make' u'man' u'manag' u'market' u'marri' u'media'\n",
      " u'meet' u'midwif' u'montag' u'mother' u'movement' u'murder' u'nation'\n",
      " u'new' u'night' u'offic' u'onli' u'order' u'org' u'pioneer' u'plan'\n",
      " u'polar' u'polic' u'polici' u'polio' u'polit' u'politician' u'pride'\n",
      " u'promin' u'realiz' u'recycl' u'ref' u'rescu' u'retrospect' u'return'\n",
      " u'reveal' u'ringsid' u'room' u'root' u'run' u'save' u'send' u'shoot'\n",
      " u'shown' u'solar' u'son' u'soon' u'stay' u'stop' u'tell' u'tenac' u'titl'\n",
      " u'today' u'tour' u'tourism' u'town' u'tradit' u'transit' u'tri'\n",
      " u'trillion' u'turn' u'union' u'unpreced' u'url' u'variou' u'verite'\n",
      " u'violenc' u'walru' u'want' u'web' u'western' u'whale' u'wife' u'www']\n",
      "grid search best score =  0.370393361981\n",
      "grid search best param =  {'selector__percentile': 12}\n",
      "score on training data =  0.422471910112\n"
     ]
    }
   ],
   "source": [
    "mostImportantFeatrures(X_wrangle_4, genreDF.Documentary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is the same and, although there is a slightly greater ammount of overfitting, it makes sense to remove digits from the data set. Finally we need to transofmr the vectorised synopsis data into an numpy array and then bring all the steps together into a preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transformToNp(X):\n",
    "    return X.as_matrix().flatten()\n",
    "\n",
    "transformToNpTransform = FunctionTransformer(transformToNp, validate=False)\n",
    "\n",
    "X_wrangled = transformToNpTransform.fit_transform(X_wrangle_4)\n",
    "\n",
    "preprocessing = Pipeline([(\"deleteTags\", deleteSynopsisTagsTransformer), \n",
    "                          (\"deleteCapitalizedWords\", noCapsTransform), \n",
    "                          (\"porterStemmer\", stemTransform),\n",
    "                          (\"deleteDigits\", noDigitsTransform),\n",
    "                          (\"toNumpy\", transformToNpTransform)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dummy model and a reasonable baseline.\n",
    "\n",
    "Before writing the dummy model I said I would first generalize the f1 score for multilabel classification. We can calculate the f1 score for each movie by comparing the predicted and actual genres (and ignoring labels that are absent from both). I then average the score over all movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def averageF1Micro(y, yPredicted, **kwargs):\n",
    "    #if a row in y has no labels assume that its genres were not in the training set and give 0\n",
    "    return np.mean([f1_score(sub_y, sub_ypredicted, labels=[1], average='micro') \n",
    "                    if sum(sub_ypredicted)!=0 else 0 \n",
    "                    for sub_y, sub_ypredicted in zip(y,yPredicted) if sum(sub_y)!=0] )\n",
    "\n",
    "averageF1MicroScorer = make_scorer(averageF1Micro, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An appropriate dummy model for a multilabel classification might be to predict the most frequently occuring labels in the data. So let's find the most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nMostFrequent(n):\n",
    "    assert(n>0)\n",
    "    frequencies=(genreDF.sum()/genreDF.count())\n",
    "    nMostFrequent = (frequencies.sort_values()[-n:]).index.tolist()\n",
    "    return nMostFrequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five most frequent labels are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Crime', u'Romance', u'Thriller', u'Comedy', u'Drama']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nMostFrequent(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can find the most frequent labels, it is not clear how many give the best fit. So our dummy model will predict the n most frquent labels for each movie and, using cross validation, we'll find the number that gives the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class nMostFrequentClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n=1):\n",
    "        self.n = n\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.occurences_ = np.sum(y, axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        cutOffVal = np.sort(self.occurences_, axis=0)[-self.n]\n",
    "        if (self.occurences_==cutOffVal).sum()==1:\n",
    "            self.nMostFrequent_ = self.occurences_>=cutOffVal\n",
    "        else:\n",
    "            additionalToSelect = self.n - (self.occurences_>cutOffVal).sum()\n",
    "            indexesOfAdditionals = np.argwhere(np.array([0,1,1,1])==1)[:additionalToSelect]\n",
    "            additionals = np.array([[1 if i in indexesOfAdditionals else 0 for i in range(len(self.occurences_))]])\n",
    "            self.nMostFrequent_ = additionals + self.occurences_>cutOffVal\n",
    "        numPredicted = len(X)\n",
    "        return np.array([self.nMostFrequent_.tolist()]*numPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try predicting up to the 10 most frequent labels and plotting the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "    best score 0.359050338086\n",
      "    best param {'nMostFrequent__n': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "pipeDummy = Pipeline([(\"nMostFrequent\", nMostFrequentClassifier())])\n",
    "\n",
    "dummCV = GridSearchCV(pipeDummy, param_grid={\"nMostFrequent__n\":[1,2,3,4,5,6,7,8,9,10]}, \n",
    "                          scoring=averageF1MicroScorer, verbose=1, \n",
    "                          refit=False, n_jobs=-1, cv=3)\n",
    "dummCV.fit(X_wrangled, y_train)\n",
    "print \"    best score\", dummCV.best_score_\n",
    "print \"    best param\", dummCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24, 0.38)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbqQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119da9c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), dummCV.cv_results_[\"mean_test_score\"])\n",
    "plt.ylabel(\"test score\")\n",
    "plt.xlabel(\"n most frequent predictors\")\n",
    "plt.xlim([0.5, 10.5])\n",
    "plt.ylim([0.24, 0.38])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see our dummy model has a best score of 0.35 which occurs when it predicts the 2 most frquent genres for every movie. Any other model has to beat this to be of value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multilabel classification classes \n",
    "\n",
    "Most machine learning algorithms do not natively support multiple labels. I need to write a number of classes that will help us adapt these standard algorithms for our purposes. \n",
    "\n",
    "Since I will be applying the machine learning algorithms to each label, some of which may appear only a small number of times in the data, I need a class that will not attempt to fit an impossibly small data set and instead will just return zero. This is the `MinSampleClassifier` and it takes an algorithm, a cutoff below which models will not be fitted and a description of wither the underlying algorithm has a decision function or a predict probability method. This last arguement will used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MinSampleClassifier(BaseEstimator, MetaEstimatorMixin):\n",
    "    def __init__(self, clf=MultinomialNB(), limit=10, decisionFunction=False):\n",
    "        self.clf = clf\n",
    "        self.limit = limit\n",
    "        self.decisionFunction = decisionFunction\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if sum(y)<self.limit:\n",
    "            self.dataTooSmall_ = True\n",
    "        else:\n",
    "            self.dataTooSmall_ = False\n",
    "            self.clf.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.dataTooSmall_:\n",
    "            return np.array([np.array([0.])]*X.shape[0])\n",
    "        else:\n",
    "            return self.clf.predict(X)\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        if self.dataTooSmall_:\n",
    "            return np.array([np.array([0.])]*X.shape[0])\n",
    "        elif self.decisionFunction:\n",
    "            return self.clf.decision_function(X)\n",
    "        else:\n",
    "            return self.clf.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models fall in to two categories. Those, like naive bayes, which can predict the proability that a given data point has a specific label and those that use a decision function. In both cases there is a cutoff value below which a data point is deemed by the model not to have that label, for approaches that predict a probability that value is 0.5 and for models that have a decision function the value is 0 (which is the distance from some decision boundary). However thse values may not lead to the best f1 score and I would like to be able to tune the threshold to get the best fit. \n",
    "\n",
    "I will create a two step process. First I will take a machine learning algorithm and use it to transform the data into a measure of fit, either a probability or a decision function score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PredictionTransformer(BaseEstimator, TransformerMixin, MetaEstimatorMixin):\n",
    "    def __init__(self, clf=MultinomialNB(), decisionFunction=True):\n",
    "        \"\"\"Replaces all features with `clf.predict_proba(X)`\"\"\"\n",
    "        self.clf = clf\n",
    "        self.decisionFunction=decisionFunction\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.decisionFunction:\n",
    "            return self.clf.decision_function(X)\n",
    "        else:\n",
    "            X_array = np.asarray(X)\n",
    "            probs = self.clf.predict_proba(X)\n",
    "            return [val[:,1] if val.shape[1]==2 else [0]*val.shape[0] for val in probs ]\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will create a class that allows the value of the threshold to be raised or lowered. However this may lead to situations where no labels are predicted. In this case I want to predict the n labels with the highest scores or probabilities, even if those are quite low. An alternative method would be to predict the n most frequent labels if none have a sufficiently high probability. I found that this alternative lead to inferior results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def thresholdCalc(threshold, minCount, x):\n",
    "        #predict values above a threshold or else the most confident minCount\n",
    "    initialThreshold = x>=threshold\n",
    "    if initialThreshold.sum() >=minCount:\n",
    "        return initialThreshold\n",
    "    else:\n",
    "        indexes = np.argpartition(x, -minCount)[-minCount:]\n",
    "        lowerThreshold = x[indexes].min()\n",
    "        if lowerThreshold>0 and minCount<len(x):\n",
    "            return x>=lowerThreshold\n",
    "        else:\n",
    "            return x>0\n",
    "        \n",
    "class ThresholdClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, threshold=0.5, minCount = 2, transpose=True):\n",
    "        \"\"\"Classify samples based on whether they are above of below `threshold`\"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.minCount = minCount\n",
    "        self.transpose=transpose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_array = np.asarray(X)\n",
    "        if self.transpose:\n",
    "            returnVal = np.array([thresholdCalc(self.threshold, self.minCount, sub) for sub in X_array]).T\n",
    "        else:\n",
    "            returnVal = np.array([thresholdCalc(self.threshold, self.minCount, sub) for sub in X_array])\n",
    "        return returnVal\n",
    "    \n",
    "    #This method is required by the OneVsRestClassifier \n",
    "    def predict_proba(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining and tuning models\n",
    "\n",
    "All of the models we are going to try will have a number of parameters that must be tuned using cross validation. Rather than repeat this boiler plate code for each model I will create a simple function that searches the available parameter space for the best values printing out the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "def crossValidateRandom(X, Y, model, params=None, n_iter=100):\n",
    "    rsCV = RandomizedSearchCV(model, param_distributions=params, n_iter=n_iter,\n",
    "                            scoring=averageF1MicroScorer, verbose=1, \n",
    "                            refit=False, n_jobs=-1, \n",
    "                            cv=3\n",
    "                           )\n",
    "    fittedModel = rsCV.fit(X, Y)\n",
    "    report(rsCV.cv_results_)\n",
    "    return rsCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model I will use the same function to vectorize the text data, called CountVectorizer. Note that an alternative vectorizer exists, tfIdfVectorizer but with it I have found that the results are not as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = CountVectorizer(lowercase=False, strip_accents='unicode', stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "This model is a staple of any attempt at text analysis. For this model I will create a naive bayes model for each genre and then use the threshold predictor to find the most likely labels.\n",
    "\n",
    "Some of the parameters I want to look at should be sampled uniformly, such as the threshold and the percentage of features needed to best predict each label. Other parameters need to be sampled unifromly in log space, such as $\\alpha$ which smoothes the likelihood function of each feature. For this I create a quick custom distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logUniform():\n",
    "    def __init__(self, low = -9, high = 0):\n",
    "        self.rng = sp_uniform(low, high-low)#This distribution is constant between `loc` and ``loc + scale``.\n",
    "        \n",
    "    def rvs(self, **kwargs):\n",
    "        return 10**(self.rng.rvs(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model first vectorizes the data. Then for each label it selects the most important features and then applies Naive Bayes. Thresholding is then used to predict the best labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 87.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.534 (std: 0.000)\n",
      "Parameters: {'count__max_df': 1.2160347144776193, 'count__min_df': 2, 'threshold__threshold': 0.36453455485863784, 'model__clf__estimator__clf__selector__percentile': 77, 'model__clf__estimator__clf__prediction__fit_prior': True, 'model__clf__estimator__clf__prediction__alpha': 0.023322323260927785, 'threshold__minCount': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.531 (std: 0.001)\n",
      "Parameters: {'count__max_df': 0.910852384228504, 'count__min_df': 3, 'threshold__threshold': 0.39987217637769384, 'model__clf__estimator__clf__selector__percentile': 81, 'model__clf__estimator__clf__prediction__fit_prior': True, 'model__clf__estimator__clf__prediction__alpha': 0.012923051057213895, 'threshold__minCount': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.531 (std: 0.001)\n",
      "Parameters: {'count__max_df': 1.0346335818356065, 'count__min_df': 3, 'threshold__threshold': 0.3518981357946287, 'model__clf__estimator__clf__selector__percentile': 67, 'model__clf__estimator__clf__prediction__fit_prior': True, 'model__clf__estimator__clf__prediction__alpha': 0.0017480473644420462, 'threshold__minCount': 2}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.21603471448, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='eng...n=True)), ('threshold', ThresholdClassifier(minCount=2, threshold=0.364534554859, transpose=False))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectThenNBPipe = Pipeline([(\"selector\", SelectPercentile(chi2)),\n",
    "                             (\"prediction\",MultinomialNB())])\n",
    "\n",
    "multipleNB = OneVsRestClassifier(MinSampleClassifier(selectThenNBPipe, decisionFunction=False))\n",
    "\n",
    "naiveBayes = Pipeline([(\"count\",count), \n",
    "                       (\"model\", PredictionTransformer(clf=multipleNB)),\n",
    "                       (\"threshold\", ThresholdClassifier(transpose=False))])\n",
    "\n",
    "NBparams = {\"count__max_df\":sp_uniform(0.8, 1.0),\n",
    "            \"count__min_df\":sp_randint(1,4),\n",
    "            \"model__clf__estimator__clf__prediction__alpha\":logUniform(low=-12, high=0),\n",
    "            \"model__clf__estimator__clf__prediction__fit_prior\":[True, False],\n",
    "            \"model__clf__estimator__clf__selector__percentile\":sp_randint(1, 100),\n",
    "            \"threshold__threshold\":sp_uniform(0, 0.5),\n",
    "            \"threshold__minCount\":sp_randint(2, 6)\n",
    "           }\n",
    "\n",
    "NBModelBestParams = crossValidateRandom(X_wrangled, y_train, naiveBayes, params=NBparams, n_iter=120)\n",
    "naiveBayes.set_params(**NBModelBestParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a best cross validation score of 0.534 for the naive bayes model. This is a good result but we should still experiment with different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "This model is easier to apply than naive bayes since it natively copes with multiple labels. However I still need to apply thresholding. This model was very slow to fit in the presence of so 1000's of features. I found the best results came not when I found the best subset of features but instead by performing Singular Value Decomposition on the features, reducing the number of dimensions down to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 65.9min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 122.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.459 (std: 0.005)\n",
      "Parameters: {'count__max_df': 1.5133164917759248, 'count__min_df': 3, 'model__clf__min_samples_split': 2, 'prob__minCount': 3, 'model__clf__max_depth': 17, 'model__clf__n_estimators': 26, 'prob__threshold': 0.2361509105916879}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.459 (std: 0.002)\n",
      "Parameters: {'count__max_df': 1.6391434331532166, 'count__min_df': 1, 'model__clf__min_samples_split': 5, 'prob__minCount': 5, 'model__clf__max_depth': 25, 'model__clf__n_estimators': 24, 'prob__threshold': 0.22991023050066983}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.458 (std: 0.003)\n",
      "Parameters: {'count__max_df': 0.9617637557269056, 'count__min_df': 1, 'model__clf__min_samples_split': 3, 'prob__minCount': 4, 'model__clf__max_depth': 9, 'model__clf__n_estimators': 21, 'prob__threshold': 0.18574521561844803}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.51331649178, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='eng...nction=False)), ('prob', ThresholdClassifier(minCount=3, threshold=0.236150910592, transpose=True))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest = Pipeline([(\"count\", count),\n",
    "                         (\"TruncatedSVD\", TruncatedSVD(n_components=100)),\n",
    "                         (\"model\", PredictionTransformer(clf=RandomForestClassifier(), decisionFunction=False)), \n",
    "                         (\"prob\", ThresholdClassifier())\n",
    "                        ])\n",
    "\n",
    "multiRFParams={\n",
    "               \"model__clf__n_estimators\":[15, 20, 25], \n",
    "               \"model__clf__max_depth\":[10, 20, 25], \n",
    "               \"model__clf__min_samples_split\":[3,5,7],\n",
    "               \"prob__threshold\":[0.4, 0.5],\n",
    "               \"prob__minCount\":[2,3,4]\n",
    "              }\n",
    "\n",
    "randomRFParams={\n",
    "                \"count__max_df\":sp_uniform(0.8, 1.0),\n",
    "                \"count__min_df\":sp_randint(1,4),\n",
    "                \"model__clf__n_estimators\":sp_randint(10, 30),\n",
    "                \"model__clf__max_depth\":sp_randint(5, 50),\n",
    "                \"model__clf__min_samples_split\":sp_randint(2, 8),\n",
    "                \"prob__threshold\":sp_uniform(0, 0.5),\n",
    "                \"prob__minCount\":sp_randint(2, 6)\n",
    "               }\n",
    "\n",
    "randomForestBestParams = crossValidateRandom(X_wrangled, y_train, randomForest, \n",
    "                                             params=randomRFParams, n_iter=120)\n",
    "randomForest.set_params(**randomForestBestParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score of 0.459 is ok but not as good as I would have hoped given the result we saw from naive bayes. It may also be a good idea to increase the value of n_estimators the next time given that its value is quite large in all three of the best models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM models are increadibly powerful but can be very slow to fit and predict in the presence of a large number of features. This is compounded by needing to fit a sperate model for each of 40 labels. For this reason I have chosen the simple linear SVC model; more sophisticated models simply were too slow to use. The model is applied here in the same way as the naive bayes model, with feature selection and prediction for each label and thresholding to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 50.5min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 92.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.513 (std: 0.003)\n",
      "Parameters: {'count__max_df': 1.2707596485742632, 'count__min_df': 1, 'threshold__threshold': 2.2502919995225112, 'model__clf__estimator__clf__selector__percentile': 86, 'model__clf__estimator__clf__prediction__class_weight': 'balanced', 'model__clf__estimator__clf__prediction__C': 0.004397061368268012, 'model__clf__estimator__clf__prediction__loss': 'squared_hinge', 'threshold__minCount': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.512 (std: 0.002)\n",
      "Parameters: {'count__max_df': 1.3870216390065901, 'count__min_df': 3, 'threshold__threshold': 2.8855670265745874, 'model__clf__estimator__clf__selector__percentile': 70, 'model__clf__estimator__clf__prediction__class_weight': 'balanced', 'model__clf__estimator__clf__prediction__C': 0.0014959445744170343, 'model__clf__estimator__clf__prediction__loss': 'squared_hinge', 'threshold__minCount': 4}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.508 (std: 0.003)\n",
      "Parameters: {'count__max_df': 1.0651703959142567, 'count__min_df': 2, 'threshold__threshold': 3.86052884200872, 'model__clf__estimator__clf__selector__percentile': 67, 'model__clf__estimator__clf__prediction__class_weight': 'balanced', 'model__clf__estimator__clf__prediction__C': 0.0016652991745999615, 'model__clf__estimator__clf__prediction__loss': 'squared_hinge', 'threshold__minCount': 3}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.27075964857, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='eng...on=True)), ('threshold', ThresholdClassifier(minCount=5, threshold=2.25029199952, transpose=False))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectThenLinearSVCPipe = Pipeline([(\"selector\", SelectPercentile(chi2)),\n",
    "                                    (\"prediction\",LinearSVC())\n",
    "                                   ])\n",
    "\n",
    "multiplieSVC = OneVsRestClassifier(MinSampleClassifier(selectThenLinearSVCPipe, decisionFunction=True))\n",
    "\n",
    "linearSVC = Pipeline([(\"count\",count), \n",
    "                      (\"model\", PredictionTransformer(multiplieSVC)),\n",
    "                      (\"threshold\", ThresholdClassifier(transpose=False))\n",
    "                     ])\n",
    "\n",
    "randomSVCparams = {\n",
    "                   \"count__max_df\":sp_uniform(0.8, 1.0),\n",
    "                   \"count__min_df\":sp_randint(1,4),\n",
    "                   \"model__clf__estimator__clf__prediction__C\":logUniform(low=-9, high=0),\n",
    "                   \"model__clf__estimator__clf__prediction__loss\":[\"hinge\", \"squared_hinge\"],\n",
    "                   \"model__clf__estimator__clf__prediction__class_weight\":[\"balanced\", None],\n",
    "                   \"model__clf__estimator__clf__selector__percentile\":sp_randint(1, 100),\n",
    "                   \"threshold__threshold\":sp_uniform(0, 5),\n",
    "                   \"threshold__minCount\":sp_randint(2, 6)\n",
    "                  }\n",
    "\n",
    "linearSVCBestParams = crossValidateRandom(X_wrangled, y_train, linearSVC, \n",
    "                                          params=randomSVCparams, n_iter=120)\n",
    "    \n",
    "linearSVC.set_params(**linearSVCBestParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes remains the best result as the linear support vector machines best score is 0.513. Still this is a good score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Classifier\n",
    "\n",
    "Finally I use the very fast stochasitc gradient descent classifier. This model fits a linear decision function according to different loss mechanisms. For example using log loss is equivilent to fitting a logistic regression. Here I try several different loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 49.6min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 91.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.459 (std: 0.006)\n",
      "Parameters: {'count__max_df': 1.7097236586694617, 'count__min_df': 3, 'threshold__threshold': 1.1756712811088494, 'model__clf__estimator__clf__selector__percentile': 38, 'model__clf__estimator__clf__prediction__penalty': 'none', 'model__clf__estimator__clf__prediction__alpha': 1.701538531567857e-06, 'model__clf__estimator__clf__prediction__loss': 'modified_huber', 'model__clf__estimator__clf__prediction__n_iter': 4, 'threshold__minCount': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.454 (std: 0.004)\n",
      "Parameters: {'count__max_df': 1.4804515872937614, 'count__min_df': 3, 'threshold__threshold': 5.193965993540646, 'model__clf__estimator__clf__selector__percentile': 99, 'model__clf__estimator__clf__prediction__penalty': 'l2', 'model__clf__estimator__clf__prediction__alpha': 1.7985266629955536e-05, 'model__clf__estimator__clf__prediction__loss': 'modified_huber', 'model__clf__estimator__clf__prediction__n_iter': 15, 'threshold__minCount': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.454 (std: 0.009)\n",
      "Parameters: {'count__max_df': 1.4496693645692624, 'count__min_df': 3, 'threshold__threshold': 5.395635440243735, 'model__clf__estimator__clf__selector__percentile': 96, 'model__clf__estimator__clf__prediction__penalty': 'elasticnet', 'model__clf__estimator__clf__prediction__alpha': 2.3981374726082388e-05, 'model__clf__estimator__clf__prediction__loss': 'log', 'model__clf__estimator__clf__prediction__n_iter': 15, 'threshold__minCount': 5}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=False, max_df=1.70972365867, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='eng...on=True)), ('threshold', ThresholdClassifier(minCount=3, threshold=1.17567128111, transpose=False))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectThenSGDCPipe = Pipeline([(\"selector\", SelectPercentile(chi2)),\n",
    "                               (\"prediction\",SGDClassifier())\n",
    "                              ])\n",
    "\n",
    "multipleSGDC = OneVsRestClassifier(MinSampleClassifier(selectThenSGDCPipe, decisionFunction=True))\n",
    "\n",
    "SGDC = Pipeline([(\"count\",count), \n",
    "                 (\"model\", PredictionTransformer(multipleSGDC)),\n",
    "                 (\"threshold\", ThresholdClassifier(transpose=False))\n",
    "                ])\n",
    "\n",
    "SGDCparams = {\n",
    "              \"count__max_df\":sp_uniform(0.8, 1.0),\n",
    "              \"count__min_df\":sp_randint(1,4),\n",
    "              \"model__clf__estimator__clf__prediction__alpha\":logUniform(low=-9, high=0),\n",
    "              \"model__clf__estimator__clf__prediction__loss\":[\"log\", \"modified_huber\", \"perceptron\"],\n",
    "              \"model__clf__estimator__clf__prediction__penalty\":[\"none\", \"l2\", \"l1\", \"elasticnet\"],\n",
    "              \"model__clf__estimator__clf__prediction__n_iter\":sp_randint(2, 20),\n",
    "              \"model__clf__estimator__clf__selector__percentile\":sp_randint(1, 100),\n",
    "              \"threshold__threshold\":sp_uniform(1, 5),\n",
    "              \"threshold__minCount\":sp_randint(2, 6)\n",
    "             }\n",
    "\n",
    "SGDCBestParams = crossValidateRandom(X_wrangled, y_train, SGDC, \n",
    "                                         params=SGDCparams, n_iter=120)\n",
    "SGDC.set_params(**SGDCBestParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for stochastic gradient decent is the same score as from random forest, 0.459.\n",
    "\n",
    "Some of the scores we have seen have been pretty good, especially compared to the dummy baseline model of 0.36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "\n",
    "Finally let's try combining these models to see if they have stronger predictive power together. Scikit-Learn does have ensemble classifiers but none support multilabel classification so I will adapt the sklearn class `VotingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiLabelVotingClassifier(VotingClassifier):\n",
    "    def fit(self, X, Y):\n",
    "        self.estimators_ = [clf.fit(X, Y) for _, clf in self.estimators]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = self._predict(X)\n",
    "        maj = np.array([np.apply_along_axis(lambda x:np.argmax(np.bincount(x, weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=y.astype('int')).tolist() for y in predictions]).T\n",
    "        return maj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try different combinations of models and give different weights to each model. However we need to have an odd number of models (or at least the sum of the weights must be odd) to ensure that there are no ties. The weights considered are as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 1],\n",
       " [0, 0, 1, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 1, 1],\n",
       " [1, 0, 0, 0],\n",
       " [1, 0, 1, 1],\n",
       " [1, 1, 0, 1],\n",
       " [1, 1, 1, 0],\n",
       " [2, 2, 2, 1],\n",
       " [2, 2, 1, 2],\n",
       " [2, 1, 2, 2],\n",
       " [2, 1, 1, 1],\n",
       " [1, 2, 2, 2],\n",
       " [1, 2, 1, 1],\n",
       " [1, 1, 2, 1],\n",
       " [1, 1, 1, 2]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binaries = [[a,b,c,d] for a in [0,1] for b in [0,1] for c in [0,1] for d in [0,1] if (a+b+c+d)%2==1]\n",
    "sub2for0 = lambda lst : [2 if val==0 else val for val in lst]\n",
    "weights = binaries + [sub2for0(lst) for lst in binaries]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 93.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid search best score =  0.575700248579\n",
      "grid search best param =  {'weights': [1, 1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "ensembleModel =  MultiLabelVotingClassifier(estimators = [(\"NBModel\",naiveBayes),\n",
    "                                                          (\"randomForestModel\",randomForest),\n",
    "                                                          (\"linearSVCModel\",linearSVC),\n",
    "                                                          (\"SGDC\",SGDC)],\n",
    "                                            voting='hard', n_jobs = -1)\n",
    "\n",
    "ensembleParams = {\"weights\" : weights}\n",
    "ensemble = GridSearchCV(ensembleModel, param_grid=ensembleParams, \n",
    "                        scoring=customF1Scorer, verbose=1, refit=True, n_jobs=1, cv=3)\n",
    "\n",
    "ensemble.fit(X_wrangled, y_train)\n",
    "print \"grid search best score = \", ensemble.best_score_\n",
    "print \"grid search best param = \", ensemble.best_params_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great result and is better than any of the models individually. The real test though is whether we have a generalised model or if we have somehow overfitted. Therefore the crucial result is the score on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test set result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that's been constructed is fairly easy to apply. We just preprocess the data, removing extranious tags, names and digits before stemming the text. Then we just predict the genres using the ensemble model trained earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56667200679164376"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_wrangled = preprocessing.transform(X_test)\n",
    "y_test_prediction = ensemble.predict(X_test_wrangled)\n",
    "averageF1Micro(y_test, y_test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1$_{micro}$ test score = 0.57\n",
    "This is an outstanding result for multilabel learning and demonstrates the successful application of text analysis in a multilabel problem. That the test score is so close to the training score indicates good generalization of the model to unseen data. \n",
    "\n",
    "If this were a stand alone product I would say that it was ready for release in beta. There is more work that can be done, and will be discussed below, but this is a great result and a useful algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. A short discussion on future work\n",
    "\n",
    "Future work could focus on a number of different areas.\n",
    "\n",
    "I could extend the classifier either to sub-genres up front or subsequently after predicting the parent genre (hierarchical prediction). For example predicting 'Satire' or 'Slapstick' if the model predicts 'Comedy'. \n",
    "\n",
    "And looking beyond the synopsis data, I could try to improve the fit by using country and date information. On the latter I did explore but found little relation to the year a movie was released and it's likely genres, essentially the popular genres have remained at almost the same level of popularity for decades, with the one big exception being westerns and adult movies. I also explored a seasonality affect expecting that a sine wave could be fitted to genres which might be more likely to be released at certain times of the year. However while this may be true of a small number of hollywood blockbusters, it does not appear to be a trend evident in the data as a whole."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
